{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531d0b25-93e8-4788-9a9d-335c17803e36",
   "metadata": {},
   "source": [
    "## The Bag of Words representation\n",
    "![deep](https://user-images.githubusercontent.com/12748752/134754236-8d5549c9-bd05-408d-ba63-0d56ab83c999.png)\n",
    "### Common Vectorizer usage\n",
    "![light](https://user-images.githubusercontent.com/12748752/134754235-ae8efaf0-a27a-46f0-b439-b114cbb8cf3e.png)\n",
    "**CountVectorizer** implements both tokenization and occurrence counting in a single class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26207183-e457-42f8-b2c2-449a4c610209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e9241c-b47c-4389-be9f-bc30824e49e0",
   "metadata": {},
   "source": [
    "### With Default Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1638e9d-8189-48a7-a2f6-c1365e6ecb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e35ad-eda3-4668-a857-a619b1331640",
   "metadata": {},
   "source": [
    "### _Tokenization & Count_\n",
    "Let’s use it to **tokenize** and **count** the word occurrences of a minimalistic corpus of text documents:\n",
    "\n",
    "> #### The default configuration tokenizes the string by extracting words of at least 2 letters. The specific function that does this step can be requested explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f945c5-d887-4df2-8057-d73a0bda19be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "'This is the first document.',\n",
    "'This is the second second document.',\n",
    "'And the third one.',\n",
    "'Is this the first document?',\n",
    "]\n",
    "\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f27c10-4cbe-4035-8c0f-8fb2d759b535",
   "metadata": {},
   "source": [
    "### Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfbc7ab1-c195-4bd4-b707-8e035fc858db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"This is a text document to analyze.\") == (['this', 'is', 'text', 'document', 'to', 'analyze'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044822b-c1b0-42db-80e5-25d26fe73d43",
   "metadata": {},
   "source": [
    "> #### Each term found by the **analyzer** during the **fit** is assigned a unique integer index corresponding to a column in the resulting matrix. \n",
    "> #### This interpretation of the columns can be retrieved as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2f17fb7-0e6f-46e1-9cd2-e7152a97e05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 1 0 1 0 2 1 0 1]\n",
      " [1 0 0 0 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7abbc52-a3e7-4a13-9d8e-30bc2f14edea",
   "metadata": {},
   "source": [
    "> #### The converse mapping from feature name to column index is stored in the vocabulary_ attribute of the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a8f555f-1a3f-4313-a232-374dde5448fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('document')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c3ccd-7499-4692-ab80-47fbfa6909ab",
   "metadata": {},
   "source": [
    "> #### Hence words that were not seen in the training corpus will be completely ignored in future calls to the transform method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5361dd3e-ace6-49f2-bca3-a798d6aa7658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['Something completely new.']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de848663-c747-4e57-bf66-79de4c318fef",
   "metadata": {},
   "source": [
    "> #### Note that in the previous corpus, the first and the last documents have exactly the same words hence are encoded in equal vectors. In particular we lose the information that the last document is an interrogative form. To preserve some of the local ordering information we can extract 2-grams of words in addition to the 1-grams (individual words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6712b849-8870-4bee-829b-3e1089bf1a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "analyze = bigram_vectorizer.build_analyzer()\n",
    "analyze('Bi-grams are cool!') == (['bi', 'grams', 'are', 'cool', 'bi grams', 'grams are', 'are cool'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf391b6-2574-4be9-b7cf-40b2c86be3b0",
   "metadata": {},
   "source": [
    "> #### The vocabulary extracted by this vectorizer is hence much bigger and can now resolve ambiguities encoded in local positioning patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69bcb78-5b45-4e4f-baca-7b7933294f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = bigram_vectorizer.fit_transform(corpus).toarray()\n",
    "X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9ffda-a272-49f5-855b-b5ddeacd4ab5",
   "metadata": {},
   "source": [
    "> #### In particular the interrogative form “Is this” is only present in the last document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fad3765-3dcc-4cf7-8b79-468d20a0bfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_index = bigram_vectorizer.vocabulary_.get('is this')\n",
    "X_2[:, feature_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fea5cd-6018-4204-b44b-1e8779c25dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
